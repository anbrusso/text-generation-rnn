{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  1529921\n",
      "Total Vocab:  38\n",
      "Total Patterns:  1529621\n"
     ]
    }
   ],
   "source": [
    "# Small LSTM Network to Generate Text for Alice in Wonderland\n",
    "import numpy\n",
    "import re\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# load ascii text and covert to lowercase\n",
    "discordf = \"../messages/discord-messages.txt\"\n",
    "discord = open(discordf, 'r', encoding='utf-8').read()\n",
    "fbf = \"../messages/facebook-messages.txt\"\n",
    "fb = open(fbf, 'r', encoding='utf-8').read()\n",
    "essayf = \"../messages/essays.txt\"\n",
    "essay = open(essayf, 'r', encoding='utf-8').read()\n",
    "raw_text = discord.lower() + \"\\n\" + fb.lower() + \"\\n\" + essay.lower()\n",
    "raw_text = raw_text.encode(\"ascii\", \"ignore\").decode()#remove any non ascii characters.\n",
    "raw_text = re.sub(r\"[~#$%&*+;<=>\\[\\\\^_\\]`{|}0-9@/]\",\"\",raw_text)#strip out some ascii characters that aren't super important.\n",
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "#print(str(char_to_int))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 300\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 2.3113\n",
      "Epoch 00001: loss improved from inf to 2.31134, saving model to checkpoints\\weights-01-2.3113-bigger.hdf5\n",
      "5976/5976 [==============================] - 2073s 347ms/step - loss: 2.3113\n",
      "Epoch 2/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.7863\n",
      "Epoch 00002: loss improved from 2.31134 to 1.78626, saving model to checkpoints\\weights-02-1.7863-bigger.hdf5\n",
      "5976/5976 [==============================] - 2060s 345ms/step - loss: 1.7863\n",
      "Epoch 3/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.6742\n",
      "Epoch 00003: loss improved from 1.78626 to 1.67422, saving model to checkpoints\\weights-03-1.6742-bigger.hdf5\n",
      "5976/5976 [==============================] - 2061s 345ms/step - loss: 1.6742\n",
      "Epoch 4/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.6122\n",
      "Epoch 00004: loss improved from 1.67422 to 1.61223, saving model to checkpoints\\weights-04-1.6122-bigger.hdf5\n",
      "5976/5976 [==============================] - 2063s 345ms/step - loss: 1.6122\n",
      "Epoch 5/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.5712\n",
      "Epoch 00005: loss improved from 1.61223 to 1.57119, saving model to checkpoints\\weights-05-1.5712-bigger.hdf5\n",
      "5976/5976 [==============================] - 2063s 345ms/step - loss: 1.5712\n",
      "Epoch 6/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.5429\n",
      "Epoch 00006: loss improved from 1.57119 to 1.54286, saving model to checkpoints\\weights-06-1.5429-bigger.hdf5\n",
      "5976/5976 [==============================] - 2061s 345ms/step - loss: 1.5429\n",
      "Epoch 7/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.5212\n",
      "Epoch 00007: loss improved from 1.54286 to 1.52125, saving model to checkpoints\\weights-07-1.5212-bigger.hdf5\n",
      "5976/5976 [==============================] - 2060s 345ms/step - loss: 1.5212\n",
      "Epoch 8/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.5033\n",
      "Epoch 00008: loss improved from 1.52125 to 1.50334, saving model to checkpoints\\weights-08-1.5033-bigger.hdf5\n",
      "5976/5976 [==============================] - 2060s 345ms/step - loss: 1.5033\n",
      "Epoch 9/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.4875\n",
      "Epoch 00009: loss improved from 1.50334 to 1.48755, saving model to checkpoints\\weights-09-1.4875-bigger.hdf5\n",
      "5976/5976 [==============================] - 2104s 352ms/step - loss: 1.4875\n",
      "Epoch 10/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.4725\n",
      "Epoch 00010: loss improved from 1.48755 to 1.47247, saving model to checkpoints\\weights-10-1.4725-bigger.hdf5\n",
      "5976/5976 [==============================] - 2095s 351ms/step - loss: 1.4725\n",
      "Epoch 11/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.4615\n",
      "Epoch 00011: loss improved from 1.47247 to 1.46151, saving model to checkpoints\\weights-11-1.4615-bigger.hdf5\n",
      "5976/5976 [==============================] - 2090s 350ms/step - loss: 1.4615\n",
      "Epoch 12/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.4504\n",
      "Epoch 00012: loss improved from 1.46151 to 1.45038, saving model to checkpoints\\weights-12-1.4504-bigger.hdf5\n",
      "5976/5976 [==============================] - 2090s 350ms/step - loss: 1.4504\n",
      "Epoch 13/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.4423\n",
      "Epoch 00013: loss improved from 1.45038 to 1.44232, saving model to checkpoints\\weights-13-1.4423-bigger.hdf5\n",
      "5976/5976 [==============================] - 2089s 350ms/step - loss: 1.4423\n",
      "Epoch 14/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.4347\n",
      "Epoch 00014: loss improved from 1.44232 to 1.43468, saving model to checkpoints\\weights-14-1.4347-bigger.hdf5\n",
      "5976/5976 [==============================] - 2089s 350ms/step - loss: 1.4347\n",
      "Epoch 15/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.4283\n",
      "Epoch 00015: loss improved from 1.43468 to 1.42830, saving model to checkpoints\\weights-15-1.4283-bigger.hdf5\n",
      "5976/5976 [==============================] - 2089s 350ms/step - loss: 1.4283\n",
      "Epoch 16/16\n",
      "5976/5976 [==============================] - ETA: 0s - loss: 1.4225\n",
      "Epoch 00016: loss improved from 1.42830 to 1.42251, saving model to checkpoints\\weights-16-1.4225-bigger.hdf5\n",
      "5976/5976 [==============================] - 2090s 350ms/step - loss: 1.4225\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(300, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(300, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(300, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#model.load_weights(\"checkpoints\\weights-04-1.6629-bigger.hdf5\")\n",
    "# define the checkpoint\n",
    "filepath=\"checkpoints/weights-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=16, batch_size=256, callbacks=callbacks_list)\n",
    "model.save(\"model-full.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(300, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(300, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(300, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.load_weights(\"checkpoints\\weights-13-1.4986-bigger.hdf5\")\n",
    "model.save('model-full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" l\n",
      "starcraft \n",
      "didn't hear that, halo  was good times\n",
      "its up there for me, probably behind  bf bad company  and tf\n",
      "https:youtu.betjr-fcgjtg?tms byun in sc is probably the most impressed i've ever been with someone's skill at a game.\n",
      "the first  mins where after where i linked is just crazy\n",
      "oh yeah, sc  \"\n",
      "\n",
      "\n",
      "\n",
      "would be a thing to the problem of the \":nd then it used to be a bit xith the problem of the agriculture that stch a and not a lot of a decent point in the ma' and then completely the  discord is because it is ) i probably don't think it was your situations and really got the slilled in the de and the ezperiment for the problem is like a social :p\n",
      "the control problem (for the s. i think it was a decent universal way to be very like ? not to be a : i need to be a bit sure that would be not in the derection in the s) i guess it was some , kind of completely many \n",
      "years ago in the sound video stuff that the first hard things me a few : xeah, i mean it was some pqoblem and then probably think about the definition of the deoends on the debate that is the svmmer and then ? lot of problems and then the best way to xou need to be a bit in the universe that the application of the means of a - in the control of the reason everything on the way to be a qython of the most of the specific beuter fo\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "#load the lstm\n",
    "model = tf.keras.models.load_model('model-full.h5')\n",
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "print(\"\\n\\n\")\n",
    "temperature = 0.04\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    predictions = model.predict(x, verbose=0)\n",
    "    \n",
    "    predictions = predictions / temperature\n",
    "    predicted_i = tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
    "    index = numpy.argmax(predictions)\n",
    "    \n",
    "    #print(\"Index: \" + str(index) + \" Predicted temp:\" + str(predicted_i))\n",
    "    \n",
    "    result = int_to_char[predicted_i]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(predicted_i)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
